library(rpart.plot)
rpart.plot(fit,type=0)
train_p=predict(fit,data=train_df$y,type="vector")
train_df$y[1:10]
train_p=replace(train_p, train_p==1, -1)
train_p=replace(train_p, train_p==2, 1)
head(train_p)
head(train_df$y)
sum(train_p==train_df$y)/length(train_p) # train success rate
# test set
test_df$y=as.factor(test_df$y)
p=predict(fit,newdata=test_df,type="vector")
# codes 0s as 2s for some reason
# run this in order!
p=replace(p, p==1, -1)
p=replace(p, p==2, 1)
head(p)
head(test_df$y)
sum(p==test_df$y)/length(p) # test success!
#boosting from ESL p. 339
create_train_data = function(n){
# create features
for(i in 1:10){
assign(paste("x", i, sep = ""), rnorm(n))
}
# create label vay (y)
y_lim=qchisq(.5,10)
y=ifelse(x1^2+x2^2+x3^2
+x4^2+x5^2+x6^2
+x7^2+x8^2
+x9^2+x10^2>y_lim,1,-1)
#plot(x1,y) # plot for fun
df = data.frame(x1,x2,x3,x4,
x5,x6,x7,x8,
x9,x10,y)
return(df)
# sum(y==1) # should be around 1000 according to ESL.
# it is
}
train_df=create_train_data(2000)
#head(train_df)
dim(train_df)
create_test_data = function(n_test){
# create features
for(i in 1:10){
assign(paste("x", i, sep = ""), rnorm(n_test))
}
# create label vay (y)
y_lim=qchisq(.5,10)
y=ifelse(x1^2+x2^2+x3^2
+x4^2+x5^2+x6^2
+x7^2+x8^2
+x9^2+x10^2>y_lim,1,-1)
#plot(x1,y) # plot for fun
df = data.frame(x1,x2,x3,x4,
x5,x6,x7,x8,
x9,x10,y)
return(df)
# sum(y==1) # should be around 1000 according to ESL.
# it is
}
test_df=create_test_data(10000)
head(test_df)
dim(test_df)
# train
# single stump
library(rpart)
set.seed((2))
train_df$y=as.factor(train_df$y)
fit <- rpart(y ~ x1+x2+x3+x4+x5+
x6+x7+x8+x9+x10,
method="class", data=train_df,
control=rpart.control(maxdepth=1))
library(rpart.plot)
rpart.plot(fit,type=0)
train_p=predict(fit,data=train_df$y,type="vector")
train_df$y[1:10]
train_p=replace(train_p, train_p==1, -1)
train_p=replace(train_p, train_p==2, 1)
head(train_p)
head(train_df$y)
sum(train_p==train_df$y)/length(train_p) # train success rate
# test set
test_df$y=as.factor(test_df$y)
p=predict(fit,newdata=test_df,type="vector")
# codes 0s as 2s for some reason
# run this in order!
p=replace(p, p==1, -1)
p=replace(p, p==2, 1)
head(p)
head(test_df$y)
sum(p==test_df$y)/length(p) # test success!
#boosting from ESL p. 339
# create train data. n = # obs= user input
create_train_data = function(n){
# create features
for(i in 1:10){
assign(paste("x", i, sep = ""), rnorm(n))
}
# create label vay (y)
y_lim=qchisq(.5,10)
y=ifelse(x1^2+x2^2+x3^2
+x4^2+x5^2+x6^2
+x7^2+x8^2
+x9^2+x10^2>y_lim,1,-1)
df = data.frame(x1,x2,x3,x4,
x5,x6,x7,x8,
x9,x10,y)
df$y=as.factor(df$y)
return(df)
# sum(y==1) # should be around 1000 according to ESL.
# it is
}
train_df=create_train_data(2000)
# create test data
# same as train
create_test_data = function(n_test){
# create features
for(i in 1:10){
assign(paste("x", i, sep = ""), rnorm(n_test))
}
# create label var (y)
y_lim=qchisq(.5,10)
y=ifelse(x1^2+x2^2+x3^2
+x4^2+x5^2+x6^2
+x7^2+x8^2
+x9^2+x10^2>y_lim,1,-1)
df = data.frame(x1,x2,x3,x4,
x5,x6,x7,x8,
x9,x10,y)
df$y=as.factor(df$y)
return(df)
# sum(y==1) # should be around 1000 according to ESL.
# it is
}
test_df=create_test_data(10000)
library(rpart)
fit <- rpart(y ~ x1+x2+x3+x4+x5+
x6+x7+x8+x9+x10,
method="class", data=train_df,
control=rpart.control(maxdepth=1))
library(rpart.plot)
rpart.plot(fit,type=0)
train_p=predict(fit,data=train_df$y,type="vector")
# replace to match -1 and 1 with training label
train_p=replace(train_p, train_p==1, -1)
train_p=replace(train_p, train_p==2, 1)
sum(train_p==train_df$y)/length(train_p) # train success rate
p=predict(fit,newdata=test_df,type="vector")
# codes 0s as 2s for some reason
# run this in order!
p=replace(p, p==1, -1)
p=replace(p, p==2, 1)
sum(p==test_df$y)/length(p) # test success!
#boosting from ESL p. 339
# create train data. n = # obs= user input
create_train_data = function(n){
# create features
for(i in 1:10){
assign(paste("x", i, sep = ""), rnorm(n))
}
# create label vay (y)
y_lim=qchisq(.5,10)
y=ifelse(x1^2+x2^2+x3^2
+x4^2+x5^2+x6^2
+x7^2+x8^2
+x9^2+x10^2>y_lim,1,-1)
df = data.frame(x1,x2,x3,x4,
x5,x6,x7,x8,
x9,x10,y)
df$y=as.factor(df$y)
return(df)
# sum(y==1) # should be around 1000 according to ESL.
# it is
}
train_df=create_train_data(2000)
# create test data
# same as train
create_test_data = function(n_test){
# create features
for(i in 1:10){
assign(paste("x", i, sep = ""), rnorm(n_test))
}
# create label var (y)
y_lim=qchisq(.5,10)
y=ifelse(x1^2+x2^2+x3^2
+x4^2+x5^2+x6^2
+x7^2+x8^2
+x9^2+x10^2>y_lim,1,-1)
df = data.frame(x1,x2,x3,x4,
x5,x6,x7,x8,
x9,x10,y)
df$y=as.factor(df$y)
return(df)
# sum(y==1) # should be around 1000 according to ESL.
# it is
}
test_df=create_test_data(10000)
# train
# single stumps. use rpart.control
library(rpart)
fit <- rpart(y ~ x1+x2+x3+x4+x5+
x6+x7+x8+x9+x10,
method="class", data=train_df,
control=rpart.control(maxdepth=1))
library(rpart.plot)
rpart.plot(fit,type=0)
train_p=predict(fit,data=train_df$y,type="vector")
# replace to match -1 and 1 with training label
train_p=replace(train_p, train_p==1, -1)
train_p=replace(train_p, train_p==2, 1)
#head(train_p)
#head(train_df$y)
sum(train_p==train_df$y)/length(train_p) # train success rate
# test set
p=predict(fit,newdata=test_df,type="vector")
# codes 0s as 2s for some reason
# run this in order!
p=replace(p, p==1, -1)
p=replace(p, p==2, 1)
#head(p)
#head(test_df$y)
success = sum(p==test_df$y)/length(p) # test success!
1-sucess # test error rate matches ESL
#boosting from ESL p. 339
# create train data. n = # obs= user input
create_train_data = function(n){
# create features
for(i in 1:10){
assign(paste("x", i, sep = ""), rnorm(n))
}
# create label vay (y)
y_lim=qchisq(.5,10)
y=ifelse(x1^2+x2^2+x3^2
+x4^2+x5^2+x6^2
+x7^2+x8^2
+x9^2+x10^2>y_lim,1,-1)
df = data.frame(x1,x2,x3,x4,
x5,x6,x7,x8,
x9,x10,y)
df$y=as.factor(df$y)
return(df)
# sum(y==1) # should be around 1000 according to ESL.
# it is
}
train_df=create_train_data(2000)
# create test data
# same as train
create_test_data = function(n_test){
# create features
for(i in 1:10){
assign(paste("x", i, sep = ""), rnorm(n_test))
}
# create label var (y)
y_lim=qchisq(.5,10)
y=ifelse(x1^2+x2^2+x3^2
+x4^2+x5^2+x6^2
+x7^2+x8^2
+x9^2+x10^2>y_lim,1,-1)
df = data.frame(x1,x2,x3,x4,
x5,x6,x7,x8,
x9,x10,y)
df$y=as.factor(df$y)
return(df)
# sum(y==1) # should be around 1000 according to ESL.
# it is
}
test_df=create_test_data(10000)
# train
# single stumps. use rpart.control
library(rpart)
fit <- rpart(y ~ x1+x2+x3+x4+x5+
x6+x7+x8+x9+x10,
method="class", data=train_df,
control=rpart.control(maxdepth=1))
library(rpart.plot)
rpart.plot(fit,type=0)
train_p=predict(fit,data=train_df$y,type="vector")
# replace to match -1 and 1 with training label
train_p=replace(train_p, train_p==1, -1)
train_p=replace(train_p, train_p==2, 1)
#head(train_p)
#head(train_df$y)
sum(train_p==train_df$y)/length(train_p) # train success rate
# test set
p=predict(fit,newdata=test_df,type="vector")
# codes 0s as 2s for some reason
# run this in order!
p=replace(p, p==1, -1)
p=replace(p, p==2, 1)
#head(p)
#head(test_df$y)
success = sum(p==test_df$y)/length(p) # test success!
1-success # test error rate matches ESL
source("make_boost_data.R")
source("make_boost_data.R")
source(make_boost_data.R)
getwd()
setwd("/Users/wnowak/wnowak10.github.io/extra_files")
getwd()
source(make_boost_data.R)
source('make_boost_data.R')
train_df=create_train_data(2000)
test_df=create_test_data(10000)
# train
# single stumps. use rpart.control
library(rpart)
fit <- rpart(y ~ x1+x2+x3+x4+x5+
x6+x7+x8+x9+x10,
method="class", data=train_df,
control=rpart.control(maxdepth=1))
library(rpart.plot)
rpart.plot(fit,type=0)
train_p=predict(fit,data=train_df$y,type="vector")
# replace to match -1 and 1 with training label
train_p=replace(train_p, train_p==1, -1)
train_p=replace(train_p, train_p==2, 1)
#head(train_p)
#head(train_df$y)
sum(train_p==train_df$y)/length(train_p) # train success rate
setwd("/Users/wnowak/wnowak10.github.io/extra_files")
source('make_boost_data.R')
train_df=create_train_data(2000)
test_df=create_test_data(10000)
# train
# single stumps. use rpart.control
library(rpart)
fit <- rpart(y ~ x1+x2+x3+x4+x5+
x6+x7+x8+x9+x10,
method="class", data=train_df,
control=rpart.control(maxdepth=1))
library(rpart.plot)
rpart.plot(fit,type=0)
source('predict_error.R')
train_error(fit,test_df)
test_error(fit,test_df)
#predict_error
train_error = function(fit,train_df){
train_p=predict(fit,data=train_df$y,type="vector")
# replace to match -1 and 1 with training label
train_p=replace(train_p, train_p==1, -1)
train_p=replace(train_p, train_p==2, 1)
#head(train_p)
#head(train_df$y)
train_success=sum(train_p==train_df$y)/length(train_p)
return(1-train_success) # train success rate
}
test_error = function(fit,test_df){
p=predict(fit,newdata=test_df,type="vector")
# codes 0s as 2s for some reason
# run this in order!
p=replace(p, p==1, -1)
p=replace(p, p==2, 1)
#head(p)
#head(test_df$y)
test_success = sum(p==test_df$y)/length(p) # test success!
return(1-test_success) # test error rate matches ESL
}
setwd("/Users/wnowak/wnowak10.github.io/extra_files")
source('make_boost_data.R')
train_df=create_train_data(2000)
test_df=create_test_data(10000)
# train
# single stumps. use rpart.control
library(rpart)
fit <- rpart(y ~ x1+x2+x3+x4+x5+
x6+x7+x8+x9+x10,
method="class", data=train_df,
control=rpart.control(maxdepth=1))
library(rpart.plot)
rpart.plot(fit,type=0)
source('predict_error.R')
train_error(fit,test_df)
test_error(fit,test_df)
# test set
boost = function(m,training_df){
n = length(training_df)
w = 1/n where n is number of training obs
for(i in seq(m)){
# fit initial tree
# assign(paste("err", i, sep = "_"), #sumwi* mistakes/ wi)
# assign(paste("alpha", i, sep = "_"), log((1-err)/err)
#  assign(paste("w", i, sep = ""), rnorm(n))
}
}
train_error(fit,train_df)
test_error(fit,test_df)
#set wd
setwd("/Users/wnowak/wnowak10.github.io/extra_files")
# create training and test data
source('make_boost_data.R')
train_df=create_train_data(2000)
test_df=create_test_data(10000)
# train model using rpart
# single stumps. use rpart.control
library(rpart)
fit <- rpart(y ~ x1+x2+x3+x4+x5+
x6+x7+x8+x9+x10,
method="class", data=train_df,
control=rpart.control(maxdepth=1))
library(rpart.plot)
rpart.plot(fit,type=0)
# find error rates
source('predict_error.R')
train_error(fit,train_df)
test_error(fit,test_df)
n = length(training_df)
n = length(train_df)
n
nrow(train_df)
n = nrow(train_df)
w = 1/n #where n is number of training obs
w
w = rep(1/n,n) #where n is number of training obs
w
fit <- rpart(y ~ x1+x2+x3+x4+x5+
x6+x7+x8+x9+x10,
method="class", data=train_df,
weights = w,
control=rpart.control(maxdepth=1)) # fit initial tree
rpart.plot(fit,type=0)
predictions= function(fit,train_df){
train_p=predict(fit,data=train_df$y,type="vector")
train_p=replace(train_p, train_p==1,-1)
train_p=replace(train_p, train_p==2,1)
return(train_p)
}
predictions=predictions(fit,train_df)
predictions
sum(predictions)
train_error_rate = function(predictions,train_df){
train_success=sum(train_p==train_df$y)/length(train_p)
return(1-train_success) # train success rate
}
train_error_rate(predictions,train_df)
predictions= function(fit,train_df){
train_p=predict(fit,data=train_df$y,type="vector")
train_p=replace(train_p, train_p==1,-1)
train_p=replace(train_p, train_p==2,1)
return(train_p)
}
predictions=predictions(fit,train_df)
sum(predictions)
train_error_rate = function(predictions,train_df){
train_success=sum(predictions==train_df$y)/length(train_p)
return(1-train_success) # train success rate
}
train_error_rate(predictions,train_df)
train_error_rate = function(predictions,train_df){
train_success=sum(predictions==train_df$y)/length(predictions)
return(1-train_success) # train success rate
}
train_error_rate(predictions,train_df)
predictions==train_df$y
sum(predictions==train_df$y)
predictions==train_df$y
tt=c("TRUE","FALSE")
www=c(5,10)
tt%%www
www%%%tt
www%*%tt
tt%*%www
www=as.matrix(www)
www
tt=as.matrix(tt)
tt
tt%*%www
www%*%tt
tt=t(tt)
tt
tt%*%www
www%*%tt
x <- 1:4
x
x %*% x
tt
tt=c("T","T","T","T")
tt
sum(tt)
tt=c("TRUE","TRUE","TRUE","TRUE")
tt
sum(tt)
predictions==train_df$y
w
w%*%(predictions==train_df$y)
sum(w)
i=9
assign(paste("err", i, sep = "_"),  w%*%(predictions==train_df$y) / sum(w)) #2b ESL p. 339
err_9
err=c()
err=c(err,w%*%(predictions==train_df$y) / sum(w))
err[1]
for(i in seq(10)){}
for(i in seq(10)){i}
for(i in seq(10)){i+1}
for(i in seq(10)){x=x+i}
x
for(i in seq(10)){x=x+i}
x
aa=0
for(i in seq(10)){aa=aa+i}
aa
for(i in seq(2)){aa=aa+i}
aa
aa=0
for(i in seq(2)){aa=aa+i}
aa
alpha=c()
alpha=c(alpha,err[i]) # reference first error (i=1)
alpha
alpha=c(alpha,err[1]) # reference first error (i=1)
alpha
