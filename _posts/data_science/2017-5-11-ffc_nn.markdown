---
layout: post
title:  "Basic Keras NN"
date:   2017-5-11 19:45:31 +0530
categories: data_science
author: "wnowak10"
comments: true
---

I've not posted in some time...but the school year is winding down, so that means that my blogging should be winding up. I spent a lot of time working on the [Fragile Families Challenge](fragilefamilieschallenge.org)...and I detail some of my struggles in training predictive models on that data in this slideshow I drew up. Do check it out.

<iframe src="https://docs.google.com/presentation/d/14DO9NXEFjr3cEwvQvEV5JHVcZwtFSFuu-9uSQZopGTo/embed?start=false&loop=false&delayms=3000" frameborder="0" width="760" height="549" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

Some of the key points in that presentation:

- I did little to no feature engineering. Really, I only did two key preprocesses: 1.) I used median imputation to replace missing values, and 2.) I used [SMOTE](http://contrib.scikit-learn.org/imbalanced-learn/generated/imblearn.over_sampling.SMOTE.html) to balance the class imbalance.
- This training data was run through XGBoost, and it did 'aight.

That is where we left off. As you can also infer from the presentation, I tried to do some elementary feature engineering, but it didn't get my any improvements in my leaderboard score.

Thus, I'm here to try something new. Neural nets, of course.

# Training using Keras Neural Network

We have super wide data. I figured I'd try to make things as simple as possible, to start.

![](/images/keras/nn_str.png?raw=true)

I connected each of the 14000+ inputs to a unique weight (using the model.add(Dense... functionality). (So there were 14000+ inputs, not just 3 as in image above.) Each input was hooked up to num_nodes number of hidden nodes (not just 4 as in image above). Then a linear combination of the activations from these hidden nodes were again linearly combined to generate prediction. I used regression, and not one hot...so the hidden nodes were combined and fed to just one final output node. 

Code looked like:

	# source activate py35
	from keras.models import Sequential
	from keras.layers import Dense
	from keras.wrappers.scikit_learn import KerasRegressor

	model = Sequential() # set up model
	num_nodes = 400
	model.add(Dense(num_nodes, 
		input_dim=x_tr.values.shape[1], 
		kernel_initializer='normal', 
		activation='relu'))
	model.add(Dense(1, activation='sigmoid', kernel_initializer='normal'))

	# X and Y are np arrays
	model.compile(loss='mean_squared_error',
		optimizer='adam')
	fitt = model.fit( X, Y, 
		batch_size=52, epochs=num_epochs, 
		verbose=1, callbacks=None, validation_split=0.1, 
		validation_data=(x_val.values,y_val.values))



{% if page.comments %}

<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//wnowak10-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

{% endif %}

