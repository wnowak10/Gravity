---
layout: post
title:  "Fragile Families Challenge Keras NN continued"
date:   2017-5-12 19:45:31 +0530
categories: data_science
author: "wnowak10"
comments: true
---

At the end of last post, I proposed trying each of these ideas.

So we're still getting no success. What to try next?
  
 - Perhaps we should standardize our features. Experts say this is pretty important, so let's try it and see if it helps.
 - Our models are flattening out in their learning pretty quickly...so we are getting suck in local minima (usually just a strategy of predict all 0). How can we avoid this?
 - We've yet to see our model output results other than 0 or 1. This makes me think I've simply made an error with my construction of the model. I could perhaps makes things easier and do 1 hot prediction. This probably makes the most sense, because material hardship is really a score out of 11. This would have the nice benefit of giving us predicted probabilities, instead of just values. 
 - Should we do deep learning? Adding layers? But how many?

 Let's give them a try, in unison. 

 Also, my previous NN was only predicting 0 and 1 values, which makes me think there's an issue with how things have been set up. So let's try to resolve all of this here:

 # Getting some decimals??

 I made some new dummy data...and tried to see if Keras regressor model would at least work there.

 Below, I code X as a seqence from 0 --> 100 by ones. Y is predicted by a sigmoid function.

 That is, Y = $\frac{1}{1+e^{X}}$

 A plot looks like:

 ![](/images/keras/sig.png?raw=true)

 When I do this, I train a model that makes a) good predictions, and b) predictions besides 0 and 1. So the model architecture is OK...so WTF is wrong with my FFC model?

 To see the code for the demo, see below:

	x=np.linspace(0,100,1000) #0-100 linearly
	def sigmoid(x):
	    return 1 / (1 + np.exp(-(x-50)))
	y = sigmoid(x)
	plt.plot(x, y)
	plt.show()

	from keras.models import Sequential
	from keras.layers.core import Dense, Activation
	from keras.layers.recurrent import LSTM
	from keras.optimizers import Adam, SGD

	model = Sequential() # set up model

	# add fully connected layer that go to num_nodes hidden nodes
	num_nodes = 1
	# model.add(Dense(num_nodes, input_dim=x_tr.values.shape[1], kernel_initializer='normal', activation='relu'))
	# model.add(Dense(num_nodes, input_dim=1, kernel_initializer='normal'))

	model.add(Dense(num_nodes, input_shape=(1,), kernel_initializer='normal'))


	model.add(Activation('relu'))

	# use linear combination of weights and values from previous layer to make numeric prediction
	# changing to sigmoid activation flattens output to 0-1
	model.add(Dense(1, activation='sigmoid', kernel_initializer='normal'))

	# minimize MSE
	model.compile(loss='mean_squared_error',
	              optimizer='adam')

	num_epochs = 100
	fitt = model.fit(x, y, batch_size=10, epochs=num_epochs, verbose=1, shuffle=True)

	model.predict(test)

	sigmoid(test)


It is always both annoying and gratifying when you run a simple proof of concept test, and it both works and doesn't. My toy code above did what I wanted it to do. It learned a sigmoid model, and made appropriate output predictions (values *between* 0 and 1). BUT, this is annoying, because I don't then know why my FFC model is not doing just that. 

Even more perplexing, if the model weren't learning it all, I'd think it would just spit out 0's. But the previous post showed that there are some outputs of 1. Why? There are no y value's of 1 in the training set, so it makes little sense to me that the model would learn to predict y = 1 in the prediction set. Hmmm...

Anyways, I'll look into other problem solving approaches in another post, in an effort to keep these things relatively brief and bite-size-able. 














I've not posted in some time...but the school year is winding down, so that means that my blogging should be winding up. I spent a lot of time working on the [Fragile Families Challenge](fragilefamilieschallenge.org)...and I detail some of my struggles in training predictive models on that data in this slideshow I drew up. Do check it out.

<iframe src="https://docs.google.com/presentation/d/14DO9NXEFjr3cEwvQvEV5JHVcZwtFSFuu-9uSQZopGTo/embed?start=false&loop=false&delayms=3000" frameborder="0" width="760" height="549" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

Some of the key points in that presentation:

- I did little to no feature engineering. Really, I only did two key preprocesses: 1.) I used median imputation to replace missing values, and 2.) I used [SMOTE](http://contrib.scikit-learn.org/imbalanced-learn/generated/imblearn.over_sampling.SMOTE.html) to balance the class imbalance.
- This training data was run through XGBoost, and it did 'aight.

That is where we left off. As you can also infer from the presentation, I tried to do some elementary feature engineering, but it didn't get my any improvements in my leaderboard score.

Thus, I'm here to try something new. Neural nets, of course. These can be a pain to train, so I want to try to document the process here for others to learn from (and for myself to reference in the future and take heart in when I have another training problem that just isn't progressing!). 

# Training using vanilla Keras neural network

We have super wide data. I figured I'd try to make things as simple as possible, to start.

![](/images/keras/nn_str.jpg?raw=true)

I connected each of the 14000+ inputs to a unique weight (using the model.add(Dense... functionality). (So there were 14000+ inputs, not just 3 as in image above.) Each input was hooked up to num_nodes number of hidden nodes (not just 4 as in image above). Then a linear combination of the activations from these hidden nodes were again linearly combined to generate prediction. I used regression, and not one hot...so the hidden nodes were combined and fed to just one final output node. 

NN model code looked like:

	# source activate py35
	from keras.models import Sequential
	from keras.layers import Dense
	from keras.wrappers.scikit_learn import KerasRegressor

	model = Sequential() # set up model
	num_nodes = 4
	model.add(Dense(num_nodes, 
		input_dim=x_tr.values.shape[1], 
		kernel_initializer='normal', 
		activation='relu'))
	model.add(Dense(1, activation='sigmoid', kernel_initializer='normal'))

	# X and Y are np arrays
	model.compile(loss='mean_squared_error',
		optimizer='adam')
	fitt = model.fit( X, Y, 
		batch_size=52, epochs=num_epochs, 
		verbose=1, callbacks=None, validation_split=0.1, 
		validation_data=(x_val.values,y_val.values))

So that didn't learn at all.

![](/images/keras/stag.png?raw=true)

And the code for preparing the predictions dataframe looked like:

	df_prediction_good_cols = df_prediction[x_tr.columns.values] # keep the columns that are in training data...
	from fancyimpute import SimpleFill
	filled = SimpleFill('median').complete(df_prediction_good_cols)
	# use trained model to predict
	preds  = model.predict(filled,verbose=1)

![](/images/keras/results400.png?raw=true)


Similarly, I tried for 4, 40, and 4000 nodes...and there was no progress. So it seems that a simple 1 layered model is not the way to go. (Or maybe the problem is just that we are only getting 0-1 outputs...how do I get some decimal action??)

# Imbalanced train set
 
 The above was with the balanced training set (with more observations for more classes). Maybe I shouldn't do that? (This reminds me of the classic Seinfeld scene, which they unfortunately cut off before the great line "you're not supposed to do that!":)
 
 <iframe width="560" height="315" src="https://www.youtube.com/embed/lj79K60ahhQ" frameborder="0" allowfullscreen></iframe>
 
 Alas, with the imbalanced training set, we get none better...
 
# What next? 
 
 
  
 So let's try the above changes, and see if we can get our training data to over fit. Once we do that, perhaps we can back out a bit and find an optimum model.  We'll do this in another post. 



{% if page.comments %}

<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//wnowak10-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

{% endif %}

